#!/usr/bin/env python3
"""
Åirket JSON dosyalarÄ±ndaki eksik sosyal medya linklerini analiz eder
"""

import json
import os
from pathlib import Path
from collections import defaultdict

def load_company_json(file_path):
    """JSON dosyasÄ±nÄ± yÃ¼kle"""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    except Exception as e:
        print(f"âŒ Hata ({file_path}): {e}")
        return None

def check_missing_social_links(company_data):
    """Eksik sosyal medya linklerini kontrol et"""
    social_platforms = ['linkedin', 'x', 'instagram', 'facebook', 'youtube', 'github']
    missing = []

    # Social alanÄ±nÄ± kontrol et
    social = company_data.get('social', {})
    if not social:
        social = {}

    for platform in social_platforms:
        link = social.get(platform)
        if not link or not str(link).strip():
            missing.append(platform)

    return missing

def analyze_all_companies(data_dir):
    """TÃ¼m ÅŸirketleri analiz et"""
    company_files = list(Path(data_dir).glob('*.json'))

    stats = {
        'total': len(company_files),
        'with_missing': 0,
        'platform_stats': defaultdict(int),
        'companies_by_missing': defaultdict(list)
    }

    missing_details = []

    for file_path in sorted(company_files):
        company_data = load_company_json(file_path)
        if not company_data:
            continue

        missing = check_missing_social_links(company_data)

        if missing:
            stats['with_missing'] += 1
            company_name = company_data.get('name', file_path.stem)
            web = company_data.get('contact', {}).get('web', 'N/A')

            missing_details.append({
                'file': file_path.stem,
                'name': company_name,
                'web': web,
                'missing': missing,
                'missing_count': len(missing)
            })

            for platform in missing:
                stats['platform_stats'][platform] += 1

            # Eksik sayÄ±sÄ±na gÃ¶re grupla
            stats['companies_by_missing'][len(missing)].append(file_path.stem)

    return stats, missing_details

def print_analysis(stats, missing_details):
    """Analiz sonuÃ§larÄ±nÄ± yazdÄ±r"""
    print("\n" + "="*80)
    print("ğŸ“Š SOSYAL MEDYA LÄ°NKLERÄ° ANALÄ°Z RAPORU")
    print("="*80)

    print(f"\nğŸ“ Toplam Åirket: {stats['total']}")
    print(f"âš ï¸  Eksik Linki Olan Åirket: {stats['with_missing']}")
    print(f"âœ… TamamÄ± Dolu Olan Åirket: {stats['total'] - stats['with_missing']}")

    print("\n" + "-"*80)
    print("ğŸ“Š PLATFORM BAZINDA EKSÄ°K Ä°STATÄ°STÄ°KLERÄ°")
    print("-"*80)

    sorted_platforms = sorted(stats['platform_stats'].items(), key=lambda x: x[1], reverse=True)
    for platform, count in sorted_platforms:
        percentage = (count / stats['total']) * 100
        print(f"  {platform:12} : {count:4} ÅŸirkette eksik ({percentage:5.1f}%)")

    print("\n" + "-"*80)
    print("ğŸ“Š EKSÄ°K LÄ°NK SAYISINA GÃ–RE DAÄILIM")
    print("-"*80)

    for missing_count in sorted(stats['companies_by_missing'].keys(), reverse=True):
        companies = stats['companies_by_missing'][missing_count]
        print(f"  {missing_count} eksik link: {len(companies)} ÅŸirket")

    # En Ã§ok eksik olan 20 ÅŸirketi gÃ¶ster
    print("\n" + "-"*80)
    print("âš ï¸  EN Ã‡OK EKSÄ°K LÄ°NKÄ° OLAN Ä°LK 20 ÅÄ°RKET")
    print("-"*80)

    sorted_details = sorted(missing_details, key=lambda x: x['missing_count'], reverse=True)[:20]

    for i, detail in enumerate(sorted_details, 1):
        print(f"\n{i}. {detail['name']}")
        print(f"   ğŸ“„ Dosya: {detail['file']}.json")
        print(f"   ğŸŒ Web: {detail['web']}")
        print(f"   âš ï¸  Eksik ({detail['missing_count']}): {', '.join(detail['missing'])}")

    # Batch komut Ã¶nerileri
    print("\n" + "="*80)
    print("ğŸ’¡ TOPLU GÃœNCELLEME Ã–NERÄ°LERÄ°")
    print("="*80)

    print("\n1ï¸âƒ£  TÃ¼m eksik linkleri gÃ¼ncelle:")
    print("   python scripts/batch-update-simple.py --limit 2000")

    print("\n2ï¸âƒ£  Sadece web sitesi olan ÅŸirketleri gÃ¼ncelle:")
    print("   python scripts/batch-update-simple.py --limit 2000")

    print("\n3ï¸âƒ£  Belirli ÅŸirketleri gÃ¼ncelle (Ã¶rnekler):")
    if len(sorted_details) >= 5:
        example_companies = '|'.join([d['file'] for d in sorted_details[:5]])
        print(f'   python scripts/batch-update-simple.py --filter "{example_companies}"')

    # CSV olarak export
    print("\n" + "-"*80)
    print("ğŸ’¾ DETAYLI LÄ°STEYÄ° KAYDET")
    print("-"*80)
    print("   CSV formatÄ±nda kaydetmek iÃ§in:")
    print("   python scripts/analyze-missing-social.py --export missing-social-links.csv")

    return sorted_details

def export_to_csv(missing_details, output_file):
    """Eksik linkleri CSV olarak kaydet"""
    import csv

    with open(output_file, 'w', encoding='utf-8', newline='') as f:
        writer = csv.writer(f)
        writer.writerow(['Dosya', 'Åirket AdÄ±', 'Web Sitesi', 'Eksik Link SayÄ±sÄ±', 'Eksik Linkler'])

        # TÃ¼m ÅŸirketleri kaydet (sorted_details yerine missing_details kullan)
        for detail in sorted(missing_details, key=lambda x: x['missing_count'], reverse=True):
            writer.writerow([
                detail['file'] + '.json',
                detail['name'],
                detail['web'],
                detail['missing_count'],
                ', '.join(detail['missing'])
            ])

    print(f"\nâœ… CSV dosyasÄ± kaydedildi: {output_file}")
    print(f"   Toplam {len(missing_details)} ÅŸirket listelendi\n")

def main():
    import argparse

    parser = argparse.ArgumentParser(description='Eksik sosyal medya linklerini analiz et')
    parser.add_argument('--export', type=str, help='CSV dosyasÄ± olarak export et')
    parser.add_argument('--data-dir', type=str, default='public/data/company',
                        help='Åirket JSON dosyalarÄ±nÄ±n bulunduÄŸu dizin')

    args = parser.parse_args()

    print("ğŸ” Åirket dosyalarÄ± taranÄ±yor...\n")

    stats, missing_details = analyze_all_companies(args.data_dir)
    sorted_details = print_analysis(stats, missing_details)

    if args.export:
        # Export iÃ§in orijinal missing_details kullan (tÃ¼mÃ¼)
        export_to_csv(missing_details, args.export)

if __name__ == '__main__':
    main()
